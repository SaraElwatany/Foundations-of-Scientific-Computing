{"cells":[{"cell_type":"markdown","source":["# Some Useful Links:\n","\n","### Pytorch Broadcasting Semantics:\n","- https://docs.python.org/3/library/operator.html"],"metadata":{"id":"yaapmmxpaVc3"}},{"cell_type":"markdown","metadata":{"id":"tBwQCEU4uVDe"},"source":["\n","# Lectures 7 and 8: Building Autograd engine from scratch\n","\n","## Learning outcomes\n","\n","1. Understanding Automated Differentiation Engines at a foundation level\n","2. Operator Overloading in OOP\n","3. Graph Representation\n","4. Graph Traversal"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gy-WPROxuNxR","executionInfo":{"status":"ok","timestamp":1704777349330,"user_tz":-120,"elapsed":266,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[],"source":["from random import Random\n","from math import sqrt\n","from uuid import uuid4\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"X5rcU5KyhLk8","executionInfo":{"status":"ok","timestamp":1704777349611,"user_tz":-120,"elapsed":3,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[],"source":["# Code Copied from previous lectures\n","SEED = 5\n","\n","random_gen = Random(x = SEED)\n","def generate_points(N = 1000):\n","    lst_x, lst_y = [], []\n","    for _ in range(N):\n","        lst_x.append(random_gen.uniform(a = 0, b = 1))\n","    for _ in range(N):\n","        lst_y.append(random_gen.uniform(a = 0, b = 1))\n","    return lst_x, lst_y\n","\n","\n","def loss(x_p, y_p, batch_x, batch_y):\n","    return ( 1 / len(batch_x)) * sum( [sqrt( (x_i - x_p)**2 + (y_i - y_p)**2)\n","                                      for x_i, y_i in zip(batch_x, batch_y)])\n","\n","def calc_grad(x_p, y_p, batch_x, batch_y):\n","    sum_x , sum_y = 0., 0.\n","\n","    for x_i, y_i in zip(batch_x, batch_y):\n","        inv_sqrt = ((x_i - x_p) ** 2 + (y_i  - y_p) ** 2) ** (-0.5)\n","        sum_x += inv_sqrt * (x_i - x_p)\n","        sum_y += inv_sqrt * (y_i - y_p)\n","\n","    return -sum_x / len(batch_x), -sum_y / len(batch_x)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23aOMJodhLhH","outputId":"5a008ed1-ffab-40cf-8c66-288ed9002449","executionInfo":{"status":"ok","timestamp":1704777349612,"user_tz":-120,"elapsed":3,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Closed form: gradient for x_p -0.28245211967555384, gradient for y_p -0.5339538940488842\n","Closed_form: loss = 0.5031831004924388\n"]}],"source":["data_x, data_y = generate_points(N=100)\n","x_p, y_p = 0.3, 0.3\n","grad_x, grad_y = calc_grad(x_p, y_p, data_x, data_y)\n","cur_loss = loss(x_p, y_p, data_x, data_y)\n","print(f\"Closed form: gradient for x_p {grad_x}, gradient for y_p {grad_y}\")\n","print(f\"Closed_form: loss = {cur_loss}\")"]},{"cell_type":"markdown","metadata":{"id":"zkxkMk1tijc_"},"source":["## Pytorch as an example of Autograd engines"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3RG22vkiQbo","outputId":"ba3cad3f-b73b-4ba7-935f-c419dbf392c5","executionInfo":{"status":"ok","timestamp":1704777354162,"user_tz":-120,"elapsed":4552,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2]) torch.Size([2])\n","torch_loss: 0.39435747265815735\n","tensor([0.3000, 0.3000], requires_grad=True)\n","torch grad: tensor([ 0.2053, -0.9787])\n","torch_loss: 0.39335745573043823\n","tensor([0.2998, 0.3010], requires_grad=True)\n","torch grad: tensor([ 0.2053, -0.9787])\n"]}],"source":["import torch\n","\n","DELTA = 0.001\n","pnt = torch.tensor([0.3, 0.3])\n","pnt.requires_grad = True\n","pnt.retain_grad()\n","data_x, data_y = generate_points(N = 1)\n","data = torch.tensor([data_x, data_y])\n","data = data.t()\n","print(data.shape, pnt.shape)\n","\n","for epoch in range(2):\n","  loss_torch = torch.mean(torch.sqrt(((data - pnt)**2).sum(dim = 1)))\n","  print(f\"torch_loss: {loss_torch}\")\n","  loss_torch.backward()\n","  with torch.no_grad():\n","    print(pnt)\n","    pnt -= DELTA*pnt.grad.data\n","    print(f\"torch grad: {pnt.grad.data}\")\n","    pnt.grad.zero_()"]},{"cell_type":"markdown","metadata":{"id":"_awi2djeqrto"},"source":["## Building Autograd from scratch"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2qwFsGXNi-GK","executionInfo":{"status":"ok","timestamp":1704777354162,"user_tz":-120,"elapsed":3,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[],"source":["class comp_node:\n","  def __init__(self, val, children = [], op = \"assign\"):\n","    self.val = val\n","    self.children = children\n","    self.op = op\n","    self.grad = 0\n","    self.backward_prop = lambda : None\n","    self.identity = uuid4()\n","\n","\n","  def __to_comp_node(self, obj):\n","    if not isinstance(obj, comp_node):\n","      return comp_node(val = obj)\n","    else:\n","      return obj\n","\n","\n","  def __sub__(self, other):\n","    other = self.__to_comp_node(other)\n","    out = comp_node(val = self.val - other.val, children = [self, other] , op = \"sub\")\n","    def _backward_prop():\n","      self.grad += out.grad * 1\n","      other.grad += out.grad * (-1)\n","\n","    out.backward_prop = _backward_prop\n","    return out\n","\n","\n","  def __rsub__(self, other):\n","    other = self.__to_comp_node(other)\n","\n","    return other - self\n","\n","\n","  def __add__(self, other):\n","    other = self.__to_comp_node(other)\n","    out = comp_node(val = self.val + other.val, children = [self, other], op = \"add\")\n","\n","    def _backward_prop():\n","      self.grad += out.grad * 1\n","      other.grad += out.grad * 1\n","\n","    out.backward_prop = _backward_prop\n","    return out\n","\n","\n","  def __radd__(self, other):\n","    other = self.__to_comp_node(other)\n","    return other + self\n","\n","\n","  def __mul__(self, other):\n","    other = self.__to_comp_node(other)\n","    out = comp_node(val = self.val * other.val, children = [self, other], op = \"mult\")\n","\n","    def _backward_prop():\n","      self.grad += out.grad * (other.val)\n","      other.grad += out.grad * (self.val)\n","    out.backward_prop = _backward_prop\n","    return out\n","\n","\n","  def __rmul__(self, other):\n","    other = self.__to_comp_node(other)\n","    return other * self\n","\n","\n","\n","  def __pow__(self, exponent):\n","    if not isinstance(exponent, (int, float)):\n","      raise ValueError(\"Unsupported types\")\n","    out = comp_node(val = self.val**exponent, children = [self], op = f\"power {exponent}\")\n","    def _backward_prop():\n","      self.grad += out.grad * (exponent * self.val**(exponent - 1))\n","    out.backward_prop = _backward_prop\n","    return out\n","\n","\n","  def __eq__(self, other):\n","    return self.val == other.val\n","\n","\n","  def __repr__(self):\n","    return f\"op: {self.op} | val: {self.val: .4f} | childern: {len(self.children)} | grad: {self.grad}\"\n","\n","######################## Start New Code ########################\n","  # A unique key for each node (to be accessed from the set or the dictionary)\n","  def __hash__(self):\n","    return int(self.identity)\n","\n","  def topo_sort(self, collect_edges=False):\n","    res=[]\n","    visited= set()\n","    def visit(node):\n","      if node not in visited:\n","        visited.add(node)\n","        for child in node.children:\n","            visit(child)\n","        res.append(node)\n","    visit(self)\n","    return res\n","\n","  def backward(self):\n","    nodes = self.topo_sort()\n","    self.grad = 1\n","    for node in reversed(nodes):\n","      node.backward_prop()\n","######################## End New Code ########################\n","\n","\n","assert comp_node(val = 5).val == 5, \"Assignment failed\"\n","assert (comp_node(val = 5) - 3).val == 2\n","assert (2 - comp_node(val = 5)).val == -3\n","assert (comp_node(val = 5)**2).val == 25\n","assert (comp_node(val = 5)**2) == comp_node(val = 25)\n","assert (comp_node(val = 5) + 3).val == 8\n","assert (2 + comp_node(val = 5)).val == 7\n","assert (comp_node(val = 5) * 3).val == 15\n","assert (2 * comp_node(val = 5)).val == 10"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwC-jF2FxcKA","outputId":"bb3fbe23-6058-4ae2-b027-db5a59ceb3bb","executionInfo":{"status":"ok","timestamp":1704777355376,"user_tz":-120,"elapsed":8,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 op: power 0.5 | val:  0.4197 | childern: 1 | grad: 1\n","1 op: add | val:  0.1761 | childern: 2 | grad: 1.1914656577245382\n","2 op: power 2 | val:  0.1095 | childern: 1 | grad: 1.1914656577245382\n","3 op: power 2 | val:  0.0666 | childern: 1 | grad: 1.1914656577245382\n","4 op: sub | val: -0.3309 | childern: 2 | grad: -0.7884289557292833\n","5 op: sub | val:  0.2581 | childern: 2 | grad: 0.6151258259637875\n","6 op: assign | val:  0.3000 | childern: 0 | grad: -0.7884289557292833\n","7 op: assign | val:  0.3000 | childern: 0 | grad: 0.6151258259637875\n"]}],"source":["data_x, data_y = generate_points(N=1)\n","x_p, y_p = comp_node(val = 0.3), comp_node(val = 0.3)\n","\n","\n","def loss_graph(x_p, y_p, data_x, data_y):\n","  I_x, I_y = x_p - data_x, y_p - data_y\n","  g_x, g_y = I_x**2, I_y**2\n","  M = g_x + g_y\n","  l = M ** 0.5\n","  return l, [l, M, g_x, g_y, I_x, I_y, x_p, y_p]\n","\n","\n","l, rev_topo_order = loss_graph(x_p, y_p, data_x[0], data_y[0])\n","rev_topo_order[0].grad = 1\n","\n","for i, node in enumerate(rev_topo_order):\n","  node.backward_prop()\n","  print(i, node)"]},{"cell_type":"code","source":["#################### Start New Code ####################\n","data_x, data_y = generate_points(N=100)\n","x_p, y_p = comp_node(val = 0.3), comp_node(val = 0.3)\n","\n","def loss_graph(x_p, y_p, data_x, data_y):\n","  loss=0\n","  for x_i, y_i in zip(data_x, data_y):\n","    I_x, I_y = x_p - x_i, y_p - y_i\n","    g_x, g_y = I_x**2, I_y**2\n","    M = g_x + g_y\n","    l = M ** 0.5\n","    loss += l\n","  return (1/len(data_x)) * loss\n","\n","curr_loss = loss_graph(x_p, y_p, data_x, data_y)\n","curr_loss.backward()\n","\n","print(x_p.grad, y_p.grad)\n","#from pprint import pprint\n","#pprint(list(reversed(curr_loss.topo_sort())))\n","print(x_p.grad, y_p.grad)\n","#################### End New Code ####################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjPImHP2aypn","executionInfo":{"status":"ok","timestamp":1704725036112,"user_tz":-120,"elapsed":412,"user":{"displayName":"Sara Elwatany","userId":"13760017889074098648"}},"outputId":"83bf9546-0285-47e3-9975-1b83017e56c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-0.4495361695632005 -0.30993795041828925\n","-0.4495361695632005 -0.30993795041828925\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1RqjcfDM3xwK0i4G_dR04uimeYx2C4ay1","timestamp":1702328887971}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}